{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing your own functions\n",
    "\n",
    "*Functions*  are a group of statements that produce a new value.  They\n",
    "are a fundamental part of Scala. \n",
    "\n",
    "You've probably already seen examples of functions:  we call them *methods* when they are defined for an entire class of object.  Strings, for example have a `split` method that lets you split up a String based on a pattern you define.  The new value it prodcues is an Array of Strings.  You're not limited to these predefined functions, however.  You can define your own functions.\n",
    "\n",
    "Consider a very common challenge need when working with texts: we want to split the text of into a list of words.  We might start by defining \"word\" as \"units separated by white space\" and use the `split` method of the String class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "val gettysburg = \"\"\"Four score and   seven years ago our fathers \n",
    "brought forth, on this continent, a new nation, \n",
    "conceived in Liberty, and dedicated to the proposition \n",
    "that all men are created equal.\"\"\"\n",
    "\n",
    "gettysburg.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "This is a handy first cut, but not exactly what we want: punctuation marks are kept alongside alphabetic characters (`forth,`, `continent,`, `nation,`, `Liberty,` `equal.`), as are other white-space characters like the new line (notice the new line character kept with alphabet `brougth`, `conceived` and `that`).  Runs of more than one space character result in empty Strings (between `and` and `seven`).  To split up a String into exactly the kind of word units we want, we'll need to write our own function.\n",
    "\n",
    "## Defining a function\n",
    "\n",
    "The next cell illustrates the syntax of a function definition.  It begins with the `def` keyword followed by the name of the function (here, `naiveTokens`).  If the function needs any information to complete its task, define parameters between parentheses to supply that information.  Our word dividing function will need a String of characters to divide up, for example.  We indicate that by naming a parameter and specifying its type (the parameter named `str` will be a String).  Separated from the parameter list by a colon is the identification of what type of value our function will create.  Our result will be A Vector of String values.  \n",
    "\n",
    "We use the `=` sign to assign to this definition a series of statements grouped in curly brackets, the body of the function.  The value of the the last statement is the value that the function produces, or *returns*.  Here, the body of the function has two steps.  The first creates an expression named `wordArray` just like the preceding cell.  The second statement converts `wordArray` to a Vector.  This is the final statement of the body, so we will produce a Vector of String values, just as our function definition required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "/** Divide a String into a Vector words, original version.\n",
    "*\n",
    "* @param str String to split into words.\n",
    "*/\n",
    "def naiveTokens(str: String): Vector[String] = {\n",
    "    val wordArray = str.split(\" \")\n",
    "    wordArray.toVector\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your new function.  Of course, we haven't improved on the `split` method yet, but we'll know that we have in fact defined a function that takes one String parameter and successfully creates a Vector of String values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "// Test naiveTokens:\n",
    "naiveTokens(gettysburg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Using regular expressions for better word divisions\n",
    "\n",
    "Our function needs to solve the two distinct problems we identified above:\n",
    "\n",
    "1.  runs of multiple spaces result in empty Strings\n",
    "2.  we want to eliminate punctuation marks.\n",
    "\n",
    "We can solve both problems with a similar approach.  First, we can replace all sequences of one or more white space characters (space, tab, newline...) with a single space character.  Then when we split on the space character, we shouldn't get any empty entries.\n",
    "\n",
    "Second, we can elminate punctuation characters by replacing them with an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "/** Divide a String into a Vector words, version 1.\n",
    "*\n",
    "* @param str String to split into words.\n",
    "*/\n",
    "def wordTokens1(str: String, sorted: Boolean = false) : Vector[String] = {\n",
    "    val regularWhiteSpace = str.replaceAll(\"[\\\\s]+\", \" \")\n",
    "    val tokens = regularWhiteSpace.replaceAll(\"[^\\\\'a-zA-Z ]\",\"\").split(\" \").toVector\n",
    "    tokens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "// Test this version:\n",
    "wordTokens1(gettysburg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Add a sorting option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def wordTokens2(str: String, sorted: Boolean = false) : Vector[String] = {\n",
    "    val regularWhiteSpace = str.replaceAll(\"[\\\\s]+\", \" \")\n",
    "    val tokens = regularWhiteSpace.replaceAll(\"[^\\\\'a-zA-Z ]\",\"\").split(\" \").toVector\n",
    "    if (sorted) {\n",
    "        tokens.sortBy(tkn => tkn.toLowerCase)\n",
    "    } else {\n",
    "        tokens\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "wordTokens2(gettysburg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "wordTokens2(gettysburg, sorted = true)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
